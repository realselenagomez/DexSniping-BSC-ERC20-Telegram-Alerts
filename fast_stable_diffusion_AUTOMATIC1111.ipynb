{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import re\n",
        "from urllib.parse import urlparse\n",
        "from google.colab import output\n",
        "\n",
        "# These are the variables the code was screaming about\n",
        "mainpth = \"temp\"\n",
        "blsaphemy = \"webui\"\n",
        "# This prevents the 'inf' and 'clear_output' errors\n",
        "def inf(msg, style, width):\n",
        "    print(f\"[{style.upper()}] {msg}\")\n",
        "def clear_output():\n",
        "    output.clear()\n",
        "\n",
        "print(\"✅ Variables defined. You can now download to Temp Storage.\")"
      ],
      "metadata": {
        "id": "xD9IcKPhY5UZ",
        "outputId": "acbda238-2a4f-445b-adda-a9afef57db57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Variables defined. You can now download to Temp Storage.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Y9EBc437WDOs"
      },
      "outputs": [],
      "source": [
        "#@markdown # Connect Google Drive\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "import ipywidgets as widgets\n",
        "import os\n",
        "\n",
        "def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
        "Shared_Drive = \"\" #@param {type:\"string\"}\n",
        "#@markdown - Leave empty if you're not using a shared drive\n",
        "\n",
        "print(\"\u001b[0;33mConnecting...\")\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "if Shared_Drive!=\"\" and os.path.exists(\"/content/gdrive/Shareddrives\"):\n",
        "  mainpth=\"Shareddrives/\"+Shared_Drive\n",
        "else:\n",
        "  mainpth=\"MyDrive\"\n",
        "\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47kV9o1Ni8GH"
      },
      "source": [
        "# **Colab Pro notebook from https://github.com/TheLastBen/fast-stable-diffusion. [ComfyUI Colab](https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast_stable_diffusion_ComfyUI.ipynb)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "cellView": "form",
        "id": "CFWtw-6EPrKi",
        "outputId": "3b7c4ef2-894f-4f2d-e7fd-57a6ed43a457",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "68462501eb9b4f6b91263246e089c3f6",
            "5fc899f305e74fc38fb867ced83c4eae",
            "7b402f3108404099ac93a45b9f7e1780"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='✔ Done', disabled=True, layout=Layout(min_width='50px'), style=But…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68462501eb9b4f6b91263246e089c3f6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown # Install/Update AUTOMATIC1111 repo\n",
        "from IPython.utils import capture\n",
        "from IPython.display import clear_output\n",
        "from subprocess import getoutput\n",
        "import ipywidgets as widgets\n",
        "import sys\n",
        "import fileinput\n",
        "import os\n",
        "import time\n",
        "import base64\n",
        "import requests\n",
        "from urllib.request import urlopen, Request\n",
        "from urllib.parse import urlparse, parse_qs, unquote\n",
        "from tqdm import tqdm\n",
        "import six\n",
        "\n",
        "\n",
        "blsaphemy=base64.b64decode((\"ZWJ1aQ==\").encode('ascii')).decode('ascii')\n",
        "\n",
        "if not os.path.exists(\"/content/gdrive\"):\n",
        "  print('\u001b[1;31mGdrive not connected, using temporary colab storage ...')\n",
        "  time.sleep(4)\n",
        "  mainpth=\"MyDrive\"\n",
        "  !mkdir -p /content/gdrive/$mainpth\n",
        "  Shared_Drive=\"\"\n",
        "\n",
        "if Shared_Drive!=\"\" and not os.path.exists(\"/content/gdrive/Shareddrives\"):\n",
        "  print('\u001b[1;31mShared drive not detected, using default MyDrive')\n",
        "  mainpth=\"MyDrive\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
        "  fgitclone = \"git clone --depth 1\"\n",
        "  !git clone -q --depth 1 --branch main https://github.com/TheLastBen/diffusers\n",
        "  %mkdir -p /content/gdrive/$mainpth/sd\n",
        "  %cd /content/gdrive/$mainpth/sd\n",
        "  !git clone -q --branch master https://github.com/AUTOMATIC1111/stable-diffusion-w$blsaphemy\n",
        "  !mkdir -p /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/cache/\n",
        "  os.environ['TRANSFORMERS_CACHE']=f\"/content/gdrive/{mainpth}/sd/stable-diffusion-w\"+blsaphemy+\"/cache\"\n",
        "  os.environ['TORCH_HOME'] = f\"/content/gdrive/{mainpth}/sd/stable-diffusion-w\"+blsaphemy+\"/cache\"\n",
        "  !mkdir -p /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/repositories\n",
        "  !git clone https://github.com/AUTOMATIC1111/stable-diffusion-w$blsaphemy-assets /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/repositories/stable-diffusion-webui-assets\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/\n",
        "  !git reset --hard\n",
        "  !git checkout master\n",
        "  time.sleep(1)\n",
        "  !rm webui.sh\n",
        "  !git pull\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ZGV_5H4xrOSp",
        "outputId": "8ed8141b-6c6c-4125-e624-34666cb97030",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2f613b12975d43f2b1c81e985685b2f8",
            "b1e63fd158964a2f9feedfc45e35fc6f",
            "dbeec14ed5f3456494b315ab4c780064"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='✔ Done', disabled=True, layout=Layout(min_width='50px'), style=But…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f613b12975d43f2b1c81e985685b2f8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown # Requirements\n",
        "\n",
        "print('\u001b[1;32mInstalling requirements...')\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  !rm -r /usr/local/lib/python3.12/dist-packages/gradio*\n",
        "  %cd /content/\n",
        "  !wget -q -i https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dependencies/A1111.txt\n",
        "  !dpkg -i *.deb\n",
        "  if not os.path.exists('/content/gdrive/'+mainpth+'/sd/stablediffusion'):\n",
        "    !tar -C /content/gdrive/$mainpth --zstd -xf sd_mrep.tar.zst\n",
        "  !tar -C / --zstd -xf gcolabdeps.tar.zst\n",
        "  !rm *.deb | rm *.zst | rm *.txt\n",
        "  if not os.path.exists('gdrive/'+mainpth+'/sd/libtcmalloc/libtcmalloc_minimal.so.4'):\n",
        "    %env CXXFLAGS=-std=c++14\n",
        "    !wget -q https://github.com/gperftools/gperftools/releases/download/gperftools-2.5/gperftools-2.5.tar.gz && tar zxf gperftools-2.5.tar.gz && mv gperftools-2.5 gperftools\n",
        "    !wget -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/Patch\n",
        "    %cd /content/gperftools\n",
        "    !patch -p1 < /content/Patch\n",
        "    !./configure --enable-minimal --enable-libunwind --enable-frame-pointers --enable-dynamic-sized-delete-support --enable-sized-delete --enable-emergency-malloc; make -j4\n",
        "    !mkdir -p /content/gdrive/$mainpth/sd/libtcmalloc && cp .libs/libtcmalloc*.so* /content/gdrive/$mainpth/sd/libtcmalloc\n",
        "    %env LD_PRELOAD=/content/gdrive/$mainpth/sd/libtcmalloc/libtcmalloc_minimal.so.4\n",
        "    %cd /content\n",
        "    !rm *.tar.gz Patch && rm -r /content/gperftools\n",
        "  else:\n",
        "    %env LD_PRELOAD=/content/gdrive/$mainpth/sd/libtcmalloc/libtcmalloc_minimal.so.4\n",
        "\n",
        "  !pip uninstall jax -y\n",
        "  !pip install wandb==0.15.12 pydantic==1.10.2 numpy==1.26 scipy==1.15.3 controlnet_aux --no-deps -qq\n",
        "  !pip install diffusers accelerate -U --no-deps -qq\n",
        "  !rm -r /usr/local/lib/python3.12/dist-packages/tensorflow*\n",
        "  os.environ['PYTHONWARNINGS'] = 'ignore'\n",
        "  !sed -i 's@text = _formatwarnmsg(msg)@text =\\\"\\\"@g' /usr/lib/python3.12/warnings.py\n",
        "  !sed -i 's@from pytorch_lightning.loggers.wandb import WandbLogger  # noqa: F401@@g' /usr/local/lib/python3.12/dist-packages/pytorch_lightning/loggers/__init__.py\n",
        "  !sed -i 's@from .mailbox import ContextCancelledError@@g' /usr/local/lib/python3.12/dist-packages/wandb/sdk/lib/retry.py\n",
        "  !sed -i 's@raise ContextCancelledError(\"retry timeout\")@print(\"retry timeout\")@g' /usr/local/lib/python3.12/dist-packages/wandb/sdk/lib/retry.py\n",
        "  !sed -i 's@globalns, localns, set()@globalns, localns, recursive_guard=set()@g' /usr/local/lib/python3.12/dist-packages/pydantic/typing.py\n",
        "\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "cellView": "form",
        "id": "p4wj_txjP3TC",
        "outputId": "82344ab6-06d3-4f66-af68-8b6d3646a7f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "a86b3478358d4e63bce5749499e59f86",
            "c425d937f6bb4b07b5c791d7ed9a6d9f",
            "02e5000f2d4e4690b1addd5d2b380a7f",
            "022eb9bc528e4c18be3175994cbcaddd",
            "37bea27ec6794b65b641a685d6b4bbd7",
            "83b143016c4c45cdb7cf6ec8a3c0fb03"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='primary', description='✔ Model already exists', disabled=True, layout=Layout(min_width='3…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a86b3478358d4e63bce5749499e59f86"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='✔ Model downloaded, using the custom model.', disabled=True, layou…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "022eb9bc528e4c18be3175994cbcaddd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown # Model Download/Load\n",
        "\n",
        "import gdown\n",
        "from gdown.download import get_url_from_gdrive_confirmation\n",
        "import re\n",
        "\n",
        "Use_Temp_Storage = True #@param {type:\"boolean\"}\n",
        "#@markdown - If not, make sure you have enough space on your gdrive\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "Model_Version = \"SDXL\" #@param [\"SDXL\", \"1.5\", \"v1.5 Inpainting\", \"V2.1-768px\"]\n",
        "\n",
        "#@markdown Or\n",
        "PATH_to_MODEL = \"\" #@param {type:\"string\"}\n",
        "#@markdown - Insert the full path of your custom model or to a folder containing multiple models\n",
        "\n",
        "#@markdown Or\n",
        "MODEL_LINK = \"https://civitai.com/api/download/models/245598\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "def getsrc(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    if parsed_url.netloc == 'civitai.com':\n",
        "        src='civitai'\n",
        "    elif parsed_url.netloc == 'drive.google.com':\n",
        "        src='gdrive'\n",
        "    elif parsed_url.netloc == 'huggingface.co':\n",
        "        src='huggingface'\n",
        "    else:\n",
        "        src='others'\n",
        "    return src\n",
        "\n",
        "src=getsrc(MODEL_LINK)\n",
        "\n",
        "def get_name(url, gdrive):\n",
        "    if not gdrive:\n",
        "        response = requests.get(url, allow_redirects=False)\n",
        "        if \"Location\" in response.headers:\n",
        "            redirected_url = response.headers[\"Location\"]\n",
        "            quer = parse_qs(urlparse(redirected_url).query)\n",
        "            if \"response-content-disposition\" in quer:\n",
        "                disp_val = quer[\"response-content-disposition\"][0].split(\";\")\n",
        "                for vals in disp_val:\n",
        "                    if vals.strip().startswith(\"filename=\"):\n",
        "                        filenm=unquote(vals.split(\"=\", 1)[1].strip())\n",
        "                        return filenm.replace(\"\\\"\",\"\")\n",
        "    else:\n",
        "        headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36\"}\n",
        "        lnk=\"https://drive.google.com/uc?id={id}&export=download\".format(id=url[url.find(\"/d/\")+3:url.find(\"/view\")])\n",
        "        res = requests.session().get(lnk, headers=headers, stream=True, verify=True)\n",
        "        res = requests.session().get(get_url_from_gdrive_confirmation(res.text), headers=headers, stream=True, verify=True)\n",
        "        content_disposition = six.moves.urllib_parse.unquote(res.headers[\"Content-Disposition\"])\n",
        "        filenm = re.search('attachment; filename=\"(.*?)\"', content_disposition).groups()[0]\n",
        "        return filenm\n",
        "\n",
        "\n",
        "def dwn(url, dst, msg):\n",
        "    file_size = None\n",
        "    req = Request(url, headers={\"User-Agent\": \"torch.hub\"})\n",
        "    u = urlopen(req)\n",
        "    meta = u.info()\n",
        "    if hasattr(meta, 'getheaders'):\n",
        "        content_length = meta.getheaders(\"Content-Length\")\n",
        "    else:\n",
        "        content_length = meta.get_all(\"Content-Length\")\n",
        "    if content_length is not None and len(content_length) > 0:\n",
        "        file_size = int(content_length[0])\n",
        "\n",
        "    with tqdm(total=file_size, disable=False, mininterval=0.5,\n",
        "              bar_format=msg+' |{bar:20}| {percentage:3.0f}%') as pbar:\n",
        "        with open(dst, \"wb\") as f:\n",
        "            while True:\n",
        "                buffer = u.read(8192)\n",
        "                if len(buffer) == 0:\n",
        "                    break\n",
        "                f.write(buffer)\n",
        "                pbar.update(len(buffer))\n",
        "            f.close()\n",
        "\n",
        "\n",
        "def sdmdls(ver, Use_Temp_Storage):\n",
        "\n",
        "  if ver=='1.5':\n",
        "    if Use_Temp_Storage:\n",
        "      os.makedirs('/content/temp_models', exist_ok=True)\n",
        "      model='/content/temp_models/v1-5-pruned-emaonly.safetensors'\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors'\n",
        "    link='https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors'\n",
        "  elif ver=='V2.1-768px':\n",
        "    if Use_Temp_Storage:\n",
        "      os.makedirs('/content/temp_models', exist_ok=True)\n",
        "      model='/content/temp_models/v2-1_768-ema-pruned.safetensors'\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/models/Stable-diffusion/v2-1_768-ema-pruned.safetensors'\n",
        "    link='https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors'\n",
        "  elif ver=='v1.5 Inpainting':\n",
        "    if Use_Temp_Storage:\n",
        "      os.makedirs('/content/temp_models', exist_ok=True)\n",
        "      model='/content/temp_models/sd-v1-5-inpainting.ckpt'\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/models/Stable-diffusion/sd-v1-5-inpainting.ckpt'\n",
        "    link='https://huggingface.co/runwayml/stable-diffusion-inpainting/resolve/main/sd-v1-5-inpainting.ckpt'\n",
        "  elif ver=='SDXL':\n",
        "    if Use_Temp_Storage:\n",
        "      os.makedirs('/content/temp_models', exist_ok=True)\n",
        "      model='/content/temp_models/sd_xl_base_1.0.safetensors'\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/models/Stable-diffusion/sd_xl_base_1.0.safetensors'\n",
        "    link='https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors'\n",
        "\n",
        "  if not os.path.exists(model):\n",
        "    !gdown --fuzzy -O $model $link\n",
        "    if os.path.exists(model):\n",
        "      clear_output()\n",
        "      inf('\\u2714 Done','success', '50px')\n",
        "    else:\n",
        "      inf('\\u2718 Something went wrong, try again','danger', \"250px\")\n",
        "  else:\n",
        "      clear_output()\n",
        "      inf('\\u2714 Model already exists','primary', '300px')\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "if (PATH_to_MODEL !=''):\n",
        "  if os.path.exists(str(PATH_to_MODEL)):\n",
        "    inf('\\u2714 Using the trained model.','success', '200px')\n",
        "\n",
        "  else:\n",
        "      while not os.path.exists(str(PATH_to_MODEL)):\n",
        "        inf('\\u2718 Wrong path, use the colab file explorer to copy the path : ','danger', \"400px\")\n",
        "        PATH_to_MODEL=input()\n",
        "      if os.path.exists(str(PATH_to_MODEL)):\n",
        "        inf('\\u2714 Using the custom model.','success', '200px')\n",
        "\n",
        "  model=PATH_to_MODEL\n",
        "\n",
        "elif MODEL_LINK != \"\":\n",
        "\n",
        "      if src=='civitai':\n",
        "         modelname=get_name(MODEL_LINK, False)\n",
        "         if Use_Temp_Storage:\n",
        "            os.makedirs('/content/temp_models', exist_ok=True)\n",
        "            model=f'/content/temp_models/{modelname}'\n",
        "         else:\n",
        "            model=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Stable-diffusion/{modelname}'\n",
        "         if not os.path.exists(model):\n",
        "            dwn(MODEL_LINK, model, 'Downloading the custom model')\n",
        "            clear_output()\n",
        "         else:\n",
        "            inf('\\u2714 Model already exists','primary', '300px')\n",
        "      elif src=='gdrive':\n",
        "         modelname=get_name(MODEL_LINK, True)\n",
        "         if Use_Temp_Storage:\n",
        "            os.makedirs('/content/temp_models', exist_ok=True)\n",
        "            model=f'/content/temp_models/{modelname}'\n",
        "         else:\n",
        "            model=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Stable-diffusion/{modelname}'\n",
        "         if not os.path.exists(model):\n",
        "            gdown.download(url=MODEL_LINK, output=model, quiet=False, fuzzy=True)\n",
        "            clear_output()\n",
        "         else:\n",
        "            inf('\\u2714 Model already exists','primary', '300px')\n",
        "      else:\n",
        "         modelname=os.path.basename(MODEL_LINK)\n",
        "         if Use_Temp_Storage:\n",
        "            os.makedirs('/content/temp_models', exist_ok=True)\n",
        "            model=f'/content/temp_models/{modelname}'\n",
        "         else:\n",
        "            model=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Stable-diffusion/{modelname}'\n",
        "         if not os.path.exists(model):\n",
        "            gdown.download(url=MODEL_LINK, output=model, quiet=False, fuzzy=True)\n",
        "            clear_output()\n",
        "         else:\n",
        "            inf('\\u2714 Model already exists','primary', '700px')\n",
        "\n",
        "      if os.path.exists(model) and os.path.getsize(model) > 1810671599:\n",
        "        inf('\\u2714 Model downloaded, using the custom model.','success', '300px')\n",
        "      else:\n",
        "        !rm model\n",
        "        inf('\\u2718 Wrong link, check that the link is valid','danger', \"300px\")\n",
        "\n",
        "else:\n",
        "  model=sdmdls(Model_Version, Use_Temp_Storage)\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Svx6Hx0iUPd1"
      },
      "outputs": [],
      "source": [
        "#@markdown # Download LoRA\n",
        "\n",
        "LoRA_LINK = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if LoRA_LINK == \"\":\n",
        "  inf('\\u2714 Nothing to do','primary', '200px')\n",
        "else:\n",
        "  os.makedirs('/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/models/Lora', exist_ok=True)\n",
        "\n",
        "  src=getsrc(LoRA_LINK)\n",
        "\n",
        "  if src=='civitai':\n",
        "      modelname=get_name(LoRA_LINK, False)\n",
        "      loramodel=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Lora/{modelname}'\n",
        "      if not os.path.exists(loramodel):\n",
        "        dwn(LoRA_LINK, loramodel, 'Downloading the LoRA model '+modelname)\n",
        "        clear_output()\n",
        "      else:\n",
        "        inf('\\u2714 Model already exists','primary', '200px')\n",
        "  elif src=='gdrive':\n",
        "      modelname=get_name(LoRA_LINK, True)\n",
        "      loramodel=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Lora/{modelname}'\n",
        "      if not os.path.exists(loramodel):\n",
        "        gdown.download(url=LoRA_LINK, output=loramodel, quiet=False, fuzzy=True)\n",
        "        clear_output()\n",
        "      else:\n",
        "        inf('\\u2714 Model already exists','primary', '200px')\n",
        "  else:\n",
        "      modelname=os.path.basename(LoRA_LINK)\n",
        "      loramodel=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Lora/{modelname}'\n",
        "      if not os.path.exists(loramodel):\n",
        "        gdown.download(url=LoRA_LINK, output=loramodel, quiet=False, fuzzy=True)\n",
        "        clear_output()\n",
        "      else:\n",
        "        inf('\\u2714 Model already exists','primary', '200px')\n",
        "\n",
        "  if os.path.exists(loramodel) :\n",
        "    inf('\\u2714 LoRA downloaded','success', '200px')\n",
        "  else:\n",
        "    inf('\\u2718 Wrong link, check that the link is valid','danger', \"300px\")\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zC3Rz1b2TBcB"
      },
      "outputs": [],
      "source": [
        "#@markdown # ControlNet\n",
        "from torch.hub import download_url_to_file\n",
        "from urllib.parse import urlparse\n",
        "import re\n",
        "from subprocess import run\n",
        "\n",
        "XL_Model = \"None\" #@param [ \"None\", \"All\", \"Canny\", \"Depth\", \"Sketch\", \"OpenPose\", \"Recolor\"]\n",
        "\n",
        "v1_Model = \"None\" #@param [ \"None\", \"All (21GB)\", \"Canny\", \"Depth\", \"Lineart\", \"MLSD\", \"Normal\", \"OpenPose\", \"Scribble\", \"Seg\", \"ip2p\", \"Shuffle\", \"Inpaint\", \"Softedge\", \"Lineart_Anime\", \"Tile\", \"T2iadapter_Models\"]\n",
        "\n",
        "v2_Model = \"None\" #@param [ \"None\", \"All\", \"Canny\", \"Depth\", \"HED\", \"OpenPose\", \"Scribble\"]\n",
        "\n",
        "#@markdown - Download/update ControlNet extension and its models\n",
        "\n",
        "def download(url, model_dir):\n",
        "\n",
        "    filename = os.path.basename(urlparse(url).path)\n",
        "    pth = os.path.abspath(os.path.join(model_dir, filename))\n",
        "    if not os.path.exists(pth):\n",
        "        print('Downloading: '+os.path.basename(url))\n",
        "        download_url_to_file(url, pth, hash_prefix=None, progress=True)\n",
        "    else:\n",
        "      print(f\"\u001b[1;32mThe model {filename} already exists\u001b[0m\")\n",
        "\n",
        "\n",
        "Canny='https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/diffusers_xl_canny_mid.safetensors'\n",
        "Depth='https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/diffusers_xl_depth_mid.safetensors'\n",
        "Sketch='https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/sai_xl_sketch_256lora.safetensors'\n",
        "OpenPose='https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/thibaud_xl_openpose_256lora.safetensors'\n",
        "Recolor='https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/sai_xl_recolor_128lora.safetensors'\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/extensions\n",
        "  if not os.path.exists('sd-w'+blsaphemy+'-controlnet'):\n",
        "    !git clone https://github.com/Mikubill/sd-w$blsaphemy-controlnet.git\n",
        "    %cd /content\n",
        "  else:\n",
        "    %cd sd-w$blsaphemy-controlnet\n",
        "    !git reset --hard\n",
        "    !git pull\n",
        "    %cd /content\n",
        "\n",
        "mdldir='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/extensions/sd-w'+blsaphemy+'-controlnet/models'\n",
        "for filename in os.listdir(mdldir):\n",
        "  if \"_sd14v1\" in filename:\n",
        "    renamed = re.sub(\"_sd14v1\", \"-fp16\", filename)\n",
        "    os.rename(os.path.join(mdldir, filename), os.path.join(mdldir, renamed))\n",
        "\n",
        "!wget -q -O CN_models.txt https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/CN_models.txt\n",
        "!wget -q -O CN_models_v2.txt https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/CN_models_v2.txt\n",
        "!wget -q -O CN_models_XL.txt https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/CN_models_XL.txt\n",
        "\n",
        "\n",
        "with open(\"CN_models.txt\", 'r') as f:\n",
        "  mdllnk = f.read().splitlines()\n",
        "with open(\"CN_models_v2.txt\", 'r') as d:\n",
        "  mdllnk_v2 = d.read().splitlines()\n",
        "with open(\"CN_models_XL.txt\", 'r') as d:\n",
        "  mdllnk_XL = d.read().splitlines()\n",
        "\n",
        "!rm CN_models.txt CN_models_v2.txt CN_models_XL.txt\n",
        "\n",
        "\n",
        "if XL_Model == \"All\":\n",
        "  for lnk_XL in mdllnk_XL:\n",
        "      download(lnk_XL, mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "elif XL_Model == \"None\":\n",
        "    pass\n",
        "    clear_output()\n",
        "    inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "else:\n",
        "  download(globals()[XL_Model], mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "\n",
        "Canny='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny.pth'\n",
        "Depth='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1p_sd15_depth.pth'\n",
        "Lineart='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_lineart.pth'\n",
        "MLSD='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_mlsd.pth'\n",
        "Normal='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_normalbae.pth'\n",
        "OpenPose='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_openpose.pth'\n",
        "Scribble='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_scribble.pth'\n",
        "Seg='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_seg.pth'\n",
        "ip2p='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11e_sd15_ip2p.pth'\n",
        "Shuffle='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11e_sd15_shuffle.pth'\n",
        "Inpaint='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_inpaint.pth'\n",
        "Softedge='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_softedge.pth'\n",
        "Lineart_Anime='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15s2_lineart_anime.pth'\n",
        "Tile='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1e_sd15_tile.pth'\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  cfgnames=[os.path.basename(url).split('.')[0]+'.yaml' for url in mdllnk_v2]\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/extensions/sd-w$blsaphemy-controlnet/models\n",
        "  for name in cfgnames:\n",
        "      run(['cp', 'cldm_v21.yaml', name])\n",
        "  %cd /content\n",
        "\n",
        "if v1_Model == \"All (21GB)\":\n",
        "  for lnk in mdllnk:\n",
        "      download(lnk, mdldir)\n",
        "  clear_output()\n",
        "\n",
        "elif v1_Model == \"T2iadapter_Models\":\n",
        "  mdllnk=list(filter(lambda x: 't2i' in x, mdllnk))\n",
        "  for lnk in mdllnk:\n",
        "      download(lnk, mdldir)\n",
        "  clear_output()\n",
        "\n",
        "elif v1_Model == \"None\":\n",
        "    pass\n",
        "    clear_output()\n",
        "\n",
        "else:\n",
        "  download(globals()[v1_Model], mdldir)\n",
        "  clear_output()\n",
        "\n",
        "Canny='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_canny.safetensors'\n",
        "Depth='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_depth.safetensors'\n",
        "HED='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_hed.safetensors'\n",
        "OpenPose='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_openposev2.safetensors'\n",
        "Scribble='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_scribble.safetensors'\n",
        "\n",
        "\n",
        "if v2_Model == \"All\":\n",
        "  for lnk_v2 in mdllnk_v2:\n",
        "      download(lnk_v2, mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "elif v2_Model == \"None\":\n",
        "    pass\n",
        "    clear_output()\n",
        "    inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "else:\n",
        "  download(globals()[v2_Model], mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "  #@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gradio\n",
        "\n",
        "# Find where gradio is actually installed\n",
        "gradio_path = os.path.dirname(gradio.__file__)\n",
        "target_file = os.path.join(gradio_path, \"blocks.py\")\n",
        "\n",
        "if os.path.exists(target_file):\n",
        "    print(f\"✅ Found it at: {target_file}\")\n",
        "    # This manually creates the backup the script is looking for\n",
        "    with open(target_file, 'r') as f:\n",
        "        content = f.read()\n",
        "    with open(target_file + '.bak', 'w') as f:\n",
        "        f.write(content)\n",
        "    print(\"✅ Backup created. The main script should work now!\")\n",
        "else:\n",
        "    print(\"❌ Could not find blocks.py. Trying an alternative fix...\")\n",
        "    !pip install --upgrade gradio==3.50.2"
      ],
      "metadata": {
        "id": "if_QSPG2ZTpq",
        "outputId": "39f1c4b4-04ef-481f-dfb4-8fdf4ab9e97a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gradio'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-506507702.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Find where gradio is actually installed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgradio_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gradio'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PjzwxTkPSPHf",
        "outputId": "540845fd-c319-4b00-fc37-10bf90759ef4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth\" to /content/gdrive/temp/sd/stable-diffusion-webui/cache/hub/checkpoints/checkpoint_liberty_with_aug.pth\n",
            "100% 5.10M/5.10M [00:00<00:00, 175MB/s]\n",
            "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.9.0+cu128 with CUDA 1208 (you have 2.10.0+cu128)\n",
            "    Python  3.10.19 (you have 3.12.12)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
            "no module 'xformers'. Processing without...\n",
            "no module 'xformers'. Processing without...\n",
            "*** Cannot import xformers\n",
            "    Traceback (most recent call last):\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/sd_hijack_optimizations.py\", line 160, in <module>\n",
            "        import xformers.ops\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/xformers/ops/__init__.py\", line 9, in <module>\n",
            "        from .fmha import (\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/xformers/ops/fmha/__init__.py\", line 10, in <module>\n",
            "        from . import (\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/xformers/ops/fmha/flash3.py\", line 110, in <module>\n",
            "        from ...flash_attn_3 import _C  # type: ignore[attr-defined]  # noqa: F401\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ImportError: /usr/local/lib/python3.12/dist-packages/xformers/flash_attn_3/_C.so: undefined symbol: _ZN3c104cuda29c10_cuda_check_implementationEiPKcS2_ib\n",
            "\n",
            "---\n",
            "Calculating sha256 for /content/temp_models/realisticVisionV60B1_v60B1VAE.safetensors: Running on local URL: https://terina-modal-forbiddingly.ngrok-free.dev\n",
            "\u001b[32m✔ Connected\n",
            "Startup time: 19.3s (import torch: 9.2s, import gradio: 3.7s, setup paths: 3.0s, initialize shared: 0.5s, other imports: 1.1s, load scripts: 0.4s, create ui: 0.5s, gradio launch: 0.6s, add APIs: 0.2s).\n",
            "fe7578cb5ee0be63aa15baa894ab5d1751ff9b5b25ef611d5fafb2186d930c30\n",
            "Loading weights [fe7578cb5e] from /content/temp_models/realisticVisionV60B1_v60B1VAE.safetensors\n",
            "Creating model from config: /content/gdrive/temp/sd/stable-diffusion-webui/configs/v1-inference.yaml\n",
            "vocab.json: 961kB [00:00, 41.6MB/s]\n",
            "merges.txt: 525kB [00:00, 102MB/s]\n",
            "special_tokens_map.json100% 389/389 [00:00<00:00, 4.45MB/s]\n",
            "tokenizer_config.json100% 905/905 [00:00<00:00, 11.1MB/s]\n",
            "config.json: 4.52kB [00:00, 18.8MB/s]\n",
            "Applying attention optimization: Doggettx... done.\n",
            "Model loaded in 13.4s (calculate hash: 9.7s, create model: 1.5s, apply weights to model: 1.2s, calculate empty prompt: 0.8s).\n",
            "100% 30/30 [00:06<00:00,  4.36it/s]\n",
            "Downloading: \"https://github.com/cszn/KAIR/releases/download/v1.0/ESRGAN.pth\" to /content/gdrive/temp/sd/stable-diffusion-webui/models/ESRGAN/ESRGAN_4x.pth\n",
            "\n",
            "100% 63.8M/63.8M [00:00<00:00, 71.7MB/s]\n",
            "tiled upscale100% 9/9 [00:03<00:00,  2.83it/s]\n",
            "  0% 0/30 [00:00<?, ?it/s]\n",
            "*** Error completing request\n",
            "*** Arguments: ('task(jn7y90640v3kqnn)', <gradio.routes.Request object at 0x7ef00fe177d0>, 'high-detail dslr portrait of Donald Trump, wearing a sharp navy blue suit and red silk tie, standing in front of an American flag, soft cinematic lighting, 8k resolution, photorealistic, highly detailed skin texture, raw photo, Fujifilm XT3, shot on 35mm lens', 'cartoon, anime, 3d render, painting, illustration, doll, plastic skin, blurry, deformed hands, extra fingers, watermark, low quality, glitchy, red eyes', [], 1, 1, 6, 512, 512, True, 0.45, 2, 'ESRGAN_4x', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 30, 'DPM++ 2M SDE', 'Automatic', False, '', 0.8, -1, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}\n",
            "    Traceback (most recent call last):\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/call_queue.py\", line 74, in f\n",
            "        res = list(func(*args, **kwargs))\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/call_queue.py\", line 53, in f\n",
            "        res = func(*args, **kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "        res = func(*args, **kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/txt2img.py\", line 109, in txt2img\n",
            "        processed = processing.process_images(p)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/processing.py\", line 847, in process_images\n",
            "        res = process_images_inner(p)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/processing.py\", line 988, in process_images_inner\n",
            "        samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/processing.py\", line 1362, in sample\n",
            "        return self.sample_hr_pass(samples, decoded_samples, seeds, subseeds, subseed_strength, prompts)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/processing.py\", line 1454, in sample_hr_pass\n",
            "        samples = self.sampler.sample_img2img(self, samples, noise, self.hr_c, self.hr_uc, steps=self.hr_second_pass_steps or self.steps, image_conditioning=image_conditioning)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 184, in sample_img2img\n",
            "        samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/sd_samplers_common.py\", line 272, in launch_sampling\n",
            "        return func()\n",
            "               ^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 184, in <lambda>\n",
            "        samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))\n",
            "                                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
            "        return func(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stablediffusion/src/k-diffusion/k_diffusion/sampling.py\", line 626, in sample_dpmpp_2m_sde\n",
            "        denoised = model(x, sigmas[i] * s_in, **extra_args)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/sd_samplers_cfg_denoiser.py\", line 249, in forward\n",
            "        x_out = self.inner_model(x_in, sigma_in, cond=make_condition_dict(cond_in, image_cond_in))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stablediffusion/src/k-diffusion/k_diffusion/external.py\", line 112, in forward\n",
            "        eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stablediffusion/src/k-diffusion/k_diffusion/external.py\", line 138, in get_eps\n",
            "        return self.inner_model.apply_model(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 22, in <lambda>\n",
            "        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))\n",
            "                                                                     ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 34, in __call__\n",
            "        return self.__sub_func(self.__orig_func, *args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/sd_hijack_unet.py\", line 50, in apply_model\n",
            "        result = orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 22, in <lambda>\n",
            "        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))\n",
            "                                                                     ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 36, in __call__\n",
            "        return self.__orig_func(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stablediffusion/ldm/models/diffusion/ddpm.py\", line 858, in apply_model\n",
            "        x_recon = self.model(x_noisy, t, **cond)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stablediffusion/ldm/models/diffusion/ddpm.py\", line 1329, in forward\n",
            "        out = self.diffusion_model(x, t, context=cc)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/sd_unet.py\", line 91, in UNetModel_forward\n",
            "        return original_forward(self, x, timesteps, context, *args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stablediffusion/ldm/modules/diffusionmodules/openaimodel.py\", line 776, in forward\n",
            "        h = module(h, emb, context)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stablediffusion/ldm/modules/diffusionmodules/openaimodel.py\", line 84, in forward\n",
            "        x = layer(x, context)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 22, in <lambda>\n",
            "        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))\n",
            "                                                                     ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 34, in __call__\n",
            "        return self.__sub_func(self.__orig_func, *args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/sd_hijack_unet.py\", line 96, in spatial_transformer_forward\n",
            "        x = block(x, context=context[i])\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stablediffusion/ldm/modules/attention.py\", line 269, in forward\n",
            "        return checkpoint(self._forward, (x, context), self.parameters(), self.checkpoint)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stablediffusion/ldm/modules/diffusionmodules/util.py\", line 116, in checkpoint\n",
            "        return func(*inputs)\n",
            "               ^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stablediffusion/ldm/modules/attention.py\", line 272, in _forward\n",
            "        x = self.attn1(self.norm1(x), context=context if self.disable_self_attn else None) + x\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/temp/sd/stable-diffusion-webui/modules/sd_hijack_optimizations.py\", line 268, in split_cross_attention_forward\n",
            "        s2 = s1.softmax(dim=-1, dtype=q.dtype)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 14.56 GiB of which 3.95 GiB is free. Including non-PyTorch memory, this process has 10.61 GiB memory in use. Of the allocated memory 6.40 GiB is allocated by PyTorch, and 4.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "\n",
            "---\n",
            "100% 30/30 [00:06<00:00,  4.79it/s]\n",
            "tiled upscale100% 9/9 [00:03<00:00,  2.85it/s]\n",
            "100% 30/30 [00:20<00:00,  1.49it/s]\n",
            "100% 30/30 [00:06<00:00,  4.72it/s]\n",
            "tiled upscale100% 9/9 [00:03<00:00,  2.81it/s]\n",
            "100% 30/30 [00:20<00:00,  1.47it/s]\n",
            "Applying attention optimization: Doggettx... done.\n",
            "Loading weights [fe7578cb5e] from /content/temp_models/realisticVisionV60B1_v60B1VAE.safetensors\n",
            "Applying attention optimization: Doggettx... done.\n",
            "Weights loaded in 4.1s (calculate hash: 1.8s, apply weights to model: 0.7s, move model to device: 1.4s).\n",
            "100% 30/30 [00:06<00:00,  4.74it/s]\n",
            "Downloading TAESD model to: /content/gdrive/temp/sd/stable-diffusion-webui/models/VAE-taesd/taesd_decoder.pth\n",
            "100% 4.69M/4.69M [00:00<00:00, 153MB/s]\n",
            "tiled upscale100% 9/9 [00:03<00:00,  2.82it/s]\n",
            "Downloading TAESD model to: /content/gdrive/temp/sd/stable-diffusion-webui/models/VAE-taesd/taesd_encoder.pth\n",
            "100% 4.69M/4.69M [00:00<00:00, 132MB/s]\n",
            "100% 30/30 [00:20<00:00,  1.46it/s]\n",
            "Restarting UI...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2026-02-25T06:23:01+0000 lvl=warn msg=\"failed to open private leg\" id=32992a641a21 privaddr=localhost:7860 err=\"dial tcp [::1]:7860: connect: connection refused\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n",
            "Running on local URL: https://terina-modal-forbiddingly.ngrok-free.dev\n",
            "\u001b[32m✔ Connected\n",
            "Startup time: 1.2s (load scripts: 0.3s, create ui: 0.7s, add APIs: 0.2s).\n",
            "100% 30/30 [00:06<00:00,  4.72it/s]\n",
            "100% 30/30 [00:06<00:00,  4.69it/s]\n",
            "100% 30/30 [00:06<00:00,  4.71it/s]\n",
            "100% 30/30 [00:06<00:00,  4.65it/s]\n",
            "100% 20/20 [00:04<00:00,  4.72it/s]\n",
            "100% 20/20 [00:04<00:00,  4.73it/s]\n"
          ]
        }
      ],
      "source": [
        "#@markdown # Start Stable-Diffusion\n",
        "from IPython.utils import capture\n",
        "import time\n",
        "import sys\n",
        "import fileinput\n",
        "from pyngrok import ngrok, conf\n",
        "import re\n",
        "\n",
        "\n",
        "Ngrok_token = \"39zBfwLeROirS0imNfMncTFxXdq_53gFEn8hrjj821s1XUjGg\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - Input your ngrok token if you want to use ngrok server\n",
        "\n",
        "User = \"\" #@param {type:\"string\"}\n",
        "Password= \"\" #@param {type:\"string\"}\n",
        "#@markdown - Add credentials to your Gradio interface (optional)\n",
        "\n",
        "auth=f\"--gradio-auth {User}:{Password}\"\n",
        "if User ==\"\" or Password==\"\":\n",
        "  auth=\"\"\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/\n",
        "  !wget -q -O extras.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-w$blsaphemy/master/modules/extras.py\n",
        "  !wget -q -O sd_models.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-w$blsaphemy/master/modules/sd_models.py\n",
        "  !wget -q -O /usr/local/lib/python3.12/dist-packages/gradio/blocks.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/AUTOMATIC1111_files/blocks.py\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/\n",
        "\n",
        "  !sed -i 's@shared.opts.data\\[\"sd_model_checkpoint\"] = checkpoint_info.title@shared.opts.data\\[\"sd_model_checkpoint\"] = checkpoint_info.title;model.half()@' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/sd_models.py\n",
        "  #!sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1)@' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/webui.py\n",
        "  !sed -i \"s@map_location='cpu'@map_location='cuda'@\" /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/extras.py\n",
        "\n",
        "  !sed -i 's@possible_sd_paths =.*@possible_sd_paths = [\\\"/content/gdrive/{mainpth}/sd/stablediffusion\\\"]@' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/paths.py\n",
        "  !sed -i 's@\\.\\.\\/@src/@g' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/paths.py\n",
        "  !sed -i 's@src/generative-models@generative-models@g' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/paths.py\n",
        "\n",
        "  !sed -i 's@print(\\\"No module.*@@' /content/gdrive/$mainpth/sd/stablediffusion/ldm/modules/diffusionmodules/model.py\n",
        "  !sed -i 's@\\[\"sd_model_checkpoint\"\\]@\\[\"sd_model_checkpoint\", \"sd_vae\", \"CLIP_stop_at_last_layers\", \"inpainting_mask_weight\", \"initial_noise_multiplier\"\\]@g' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/shared.py\n",
        "  !sed -i \"s@res = self.CLIPTextModel_from_pretrained(None@res = self.CLIPTextModel_from_pretrained(pretrained_model_name_or_path@\" /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_disable_initialization.py\n",
        "\n",
        "share=''\n",
        "if Ngrok_token!=\"\":\n",
        "  ngrok.kill()\n",
        "  srv=ngrok.connect(7860, pyngrok_config=conf.PyngrokConfig(auth_token=Ngrok_token) , bind_tls=True).public_url\n",
        "\n",
        "  for line in fileinput.input('/usr/local/lib/python3.12/dist-packages/gradio/blocks.py', inplace=True):\n",
        "    if line.strip().startswith('self.server_name ='):\n",
        "        line = f'            self.server_name = \"{srv[8:]}\"\\n'\n",
        "    if line.strip().startswith('self.protocol = \"https\"'):\n",
        "        line = '            self.protocol = \"https\"\\n'\n",
        "    if line.strip().startswith('if self.local_url.startswith(\"https\") or self.is_colab'):\n",
        "        line = ''\n",
        "    if line.strip().startswith('else \"http\"'):\n",
        "        line = ''\n",
        "    sys.stdout.write(line)\n",
        "else:\n",
        "  share='--share'\n",
        "\n",
        "ckptdir=''\n",
        "if os.path.exists('/content/temp_models'):\n",
        "  ckptdir='--ckpt-dir /content/temp_models'\n",
        "\n",
        "try:\n",
        "  model\n",
        "  if os.path.isfile(model):\n",
        "    !python /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/webui.py $share --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae  --ckpt \"$model\" --xformers $auth --disable-console-progressbars --skip-version-check $ckptdir\n",
        "  else:\n",
        "    !python /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/webui.py $share --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae  --ckpt-dir \"$model\" --xformers $auth --disable-console-progressbars --skip-version-check\n",
        "except:\n",
        "   !python /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/webui.py $share --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae --xformers $auth --disable-console-progressbars --skip-version-check $ckptdir"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# --- PASTE YOUR TOKEN BELOW ---\n",
        "Ngrok_token = \"39zBfwLeROirS0imNfMncTFxXdq_53gFEn8hrjj821s1XUjGg\"\n",
        "# ------------------------------\n",
        "\n",
        "# 1. Force the system to use the correct local path for Temp Storage\n",
        "%cd /content/sd/stable-diffusion-webui\n",
        "\n",
        "# 2. Launch with the correct arguments to bypass the Gradio error\n",
        "!python launch.py --share --ngrok {Ngrok_token} --xformers --enable-insecure-extension-access --precision full --no-half --skip-python-version-check"
      ],
      "metadata": {
        "id": "7pEWzccjZzHQ",
        "outputId": "3b3359c9-f48a-4562-de0f-cbb39c127c3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/sd/stable-diffusion-webui'\n",
            "/content\n",
            "python3: can't open file '/content/launch.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "68462501eb9b4f6b91263246e089c3f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "✔ Done",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_5fc899f305e74fc38fb867ced83c4eae",
            "style": "IPY_MODEL_7b402f3108404099ac93a45b9f7e1780",
            "tooltip": ""
          }
        },
        "5fc899f305e74fc38fb867ced83c4eae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "50px",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b402f3108404099ac93a45b9f7e1780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "2f613b12975d43f2b1c81e985685b2f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "✔ Done",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_b1e63fd158964a2f9feedfc45e35fc6f",
            "style": "IPY_MODEL_dbeec14ed5f3456494b315ab4c780064",
            "tooltip": ""
          }
        },
        "b1e63fd158964a2f9feedfc45e35fc6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "50px",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbeec14ed5f3456494b315ab4c780064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "a86b3478358d4e63bce5749499e59f86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "primary",
            "description": "✔ Model already exists",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_c425d937f6bb4b07b5c791d7ed9a6d9f",
            "style": "IPY_MODEL_02e5000f2d4e4690b1addd5d2b380a7f",
            "tooltip": ""
          }
        },
        "c425d937f6bb4b07b5c791d7ed9a6d9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "300px",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02e5000f2d4e4690b1addd5d2b380a7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "022eb9bc528e4c18be3175994cbcaddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "✔ Model downloaded, using the custom model.",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_37bea27ec6794b65b641a685d6b4bbd7",
            "style": "IPY_MODEL_83b143016c4c45cdb7cf6ec8a3c0fb03",
            "tooltip": ""
          }
        },
        "37bea27ec6794b65b641a685d6b4bbd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "300px",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83b143016c4c45cdb7cf6ec8a3c0fb03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}